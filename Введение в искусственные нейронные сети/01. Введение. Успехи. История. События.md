#Литература

### Литература
> Жанр: Машинное обучение. Анализ данных
- Глубокое обучение. Погружение в мир нейронных сетей. Автор: Николенко С., Архангельская Е., Кадурин А. 
- Глубокое обучение. Автор: Гудфеллоу Я., Бенджио И., Курвилль А. 
- Программируем с PyTorch. Создание приложений глубокого обучения. Автор: Ян Пойнтер
- Глубокое обучение с fastai и PyTorch. Автор: Ховард Джереми, Сильвейн Гуггер

### Успехи
| Дата | Успехи                                                                                                                                                                                   |
| ---- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1997 | Сильно улучшенный Deep Blue одержал в ответном матче две победы, один раз проиграл и трижды сыграл вничью, став первым компьютером, выигравшим у действующего чемпиона мира по шахматам. |
| 2016 | Ли Седоль игра в «Го» против программы AlphaGo, разработанной компанией DeepMind, которая ныне принадлежит Google. По результатам искусственный интеллект выиграл со счетом 4:1.         |
| 2019 | Система AlphaStar от Google и стартапа DeepMind, обыграла всех ведущих игроков в популярную компьютерную стратегию Starcraft II и обошла 99,8% геймеров в общем рейтинге.                |
| 2020 | Alpha Dog Fight Trials. В пяти раундах виртуального воздушного боя F-16, управляемый искусственным интеллектом, без единого поражения победил настоящего летчика ВВС США.                |

### История
- **1943г. –** Первая математическая модель нейрона и конструкции искусственной нейронной сети Уоррен Маккалохен Уолтер Питц.
- **1957 г. –** Перцептрон Розенблата.

 - **1960 г.** – Адаптивная нейронная сеть (ADALINE).
 - **1969 г. –** Проблема XOR.

- **1970 г.** – «зима искусственного интеллекта», провал проекта по машинному переводу. Время расцвета экспертных систем MYCIN
- **1986 г. –** Разработан алгоритм обратного распространения ошибки. Ансамбли нейронов. Появление архитектур сверточных сетей, рекуррентных, автокодировщиков и др. (метод был описан в [1974](https://ru.wikipedia.org/wiki/1974) г. [А. И. Галушкиным](https://ru.wikipedia.org/wiki/%D0%93%D0%B0%D0%BB%D1%83%D1%88%D0%BA%D0%B8%D0%BD,_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80_%D0%98%D0%B2%D0%B0%D0%BD%D0%BE%D0%B2%D0%B8%D1%87_(%D1%83%D1%87%D1%91%D0%BD%D1%8B%D0%B9)))
- **2006 г. –** первое обучение глубоких нейронных сетей выполнено Джеффри Хинтон в университете Торонто.
- **2014 г. – впервые представлены** GAN Ian’a Goodfellow из университета Монреаля. Yann LeCun назвал состязательную тренировку сетей «самой интересной идеей в машинном обучении за последние 10 лет»
- **2017 г. –** впервые, исследователями из [Google Brain](https://ru.wikipedia.org/wiki/Google_Brain) представлена сеть Transformer.

### События
- Увеличение количества транзисторов
- Уменьшение размеров транзисторов
- Растущие объемы данных
- Растущие объемы datasets
- Trend of state-of-the-art NLP model sizes with time 
![[../_ Assets/Pasted image 20230916104200.png]]

### Выводы
- Производительность вычислителей растет по закону Мура;
- Ежедневно в мире генерируются огромные объемы данных, которые нужно обрабатывать, что также приводит к росту размеров датасетов;
- Исследователями создаются сети все большего размера;
- Ищутся мультимодальные конструкции сетей способных решать максимально большой класс задач;
- Методы обучения с подкреплением надежно закрепили свои позиции в симуляторах, игровых средах и виртуальном пространстве.

